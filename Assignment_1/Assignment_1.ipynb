{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "MLP Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "from matplotlib import pyplot as plt\n",
    "from PreProcessor import FeatureVectorGenerator\n",
    "from Tests import FeatureVectorGeneratorTest, PickleTest\n",
    "from Utils import GetData\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the raw data by unpickling the data\n",
    "raw_data = GetData.get_train_data_all()\n",
    "raw_data_aug = GetData.get_train_data_aug()\n",
    "\n",
    "# importing the labels\n",
    "raw_labels = GetData.get_labels()\n",
    "\n",
    "# importing the test data\n",
    "raw_test_data = GetData.get_test_data()\n",
    "\n",
    "# Testing the input data\n",
    "PickleTest.test_data_all(raw_data) # to be removed\n",
    "PickleTest.test_data(raw_test_data) # to be removed\n",
    "\n",
    "PickleTest.test_labels(raw_labels) # to be removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# declaring the batch size\n",
    "batch_size = 1024\n",
    "\n",
    "# initializing x vectors\n",
    "x_train = np.zeros((raw_data[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "for i in range(0, raw_data[b'data'].shape[0], batch_size):\n",
    "    x_train[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data[b'data'][i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.zeros((raw_test_data[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "# feature vector for test data\n",
    "for i in range(0, raw_test_data[b'data'].shape[0], batch_size):\n",
    "    x_test[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_test_data[b'data'][i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug = np.zeros((raw_data_aug[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "# feature vector for augmented data\n",
    "for i in range(0, raw_data_aug[b'data'].shape[0], batch_size):\n",
    "    x_train_aug[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_aug[b'data'][i:i+batch_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the data to get y matrix\n",
    "y_train = FeatureVectorGenerator.one_hot_encoding(raw_data[b'labels'])\n",
    "y_train_aug = FeatureVectorGenerator.one_hot_encoding(raw_data_aug[b'labels'])\n",
    "\n",
    "y_test = FeatureVectorGenerator.one_hot_encoding(raw_test_data[b'labels'])\n",
    "\n",
    "# raw data without onehot encoding\n",
    "y_train_raw = raw_data[b'labels']\n",
    "y_train_raw_aug = raw_data_aug[b'labels']\n",
    "\n",
    "y_test_raw = raw_test_data[b'labels']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data using a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the train and test data\n",
    "minimum = np.min(x_train)\n",
    "scaler = np.max(x_train) - np.min(x_train)\n",
    "x_train = (x_train - minimum) / scaler\n",
    "x_test = (x_test - minimum) / scaler\n",
    "\n",
    "# normalizing the augmented train and test data\n",
    "minimum = np.min(x_train_aug)\n",
    "scaler = np.max(x_train_aug) - np.min(x_train_aug)\n",
    "x_train_aug = (x_train_aug - minimum) / scaler\n",
    "x_test_aug = (x_test - minimum) / scaler # scaled using a scaler for augmented test set "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.MLP_Model import NeuralNeworks\n",
    "\n",
    "mlp_model = NeuralNeworks(512, 64, 64, 10)\n",
    "mlp_model_aug = NeuralNeworks(512, 64, 64, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = mlp_model.fit(x_train, y_train, epochs=1000)\n",
    "\n",
    "# plotting the error vs epochs graph\n",
    "plt.plot(err)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.title('error vs epochs')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with augmented training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = mlp_model_aug.fit(x_train, y_train, epochs=1000)\n",
    "\n",
    "# plotting the error vs epochs graph\n",
    "plt.plot(err)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.title('error vs epochs')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = mlp_model.predict(x_test)\n",
    "\n",
    "acc_mlp_train = metrics.accuracy_score(y_train_raw, mlp_model.predict(x_train))\n",
    "acc_mlp_test = metrics.accuracy_score(y_test_raw, y_pred)\n",
    "\n",
    "print(\"Train set Accuracy: \", acc_mlp_train)\n",
    "print(\"Test set Accuracy: \", acc_mlp_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_aug = mlp_model_aug.predict(x_test_aug)\n",
    "\n",
    "acc_mlp_train_aug = metrics.accuracy_score(y_train_raw_aug, mlp_model_aug.predict(x_train_aug))\n",
    "acc_mlp_test_aug = metrics.accuracy_score(y_test_raw, y_pred_aug)\n",
    "\n",
    "print(\"Augmented Train set Accuracy: \", acc_mlp_train_aug)\n",
    "print(\"Augmented Test set Accuracy: \", acc_mlp_test_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Machine Learning models Using the scikit learn package\n",
    "\n",
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# creating the model\n",
    "svm_model = svm.SVC()\n",
    "svm_model_aug = svm.SVC()\n",
    "\n",
    "# training the model\n",
    "svm_model.fit(x_train, y_train_raw)\n",
    "svm_model_aug.fit(x_train_aug, y_train_raw_aug)\n",
    "\n",
    "print(\"SVM Model Trained\")\n",
    "\n",
    "# predicting\n",
    "svm_predict = svm_model.predict(x_test)\n",
    "svm_predict_aug = svm_model_aug.predict(x_test_aug)\n",
    "\n",
    "acc_svm_train = metrics.accuracy_score(y_train_raw, svm_model.predict(x_train))\n",
    "acc_svm_test = metrics.accuracy_score(y_test_raw, svm_predict)\n",
    "\n",
    "print(\"Train set Accuracy: \", acc_svm_train)\n",
    "print(\"Test set Accuracy: \", acc_svm_test)\n",
    "\n",
    "acc_svm_train_aug = metrics.accuracy_score(y_train_raw_aug, svm_model_aug.predict(x_train_aug))\n",
    "acc_svm_test_aug = metrics.accuracy_score(y_test_raw, svm_predict_aug)\n",
    "\n",
    "print(\"Augmented Train set Accuracy: \", acc_svm_train_aug)\n",
    "print(\"Augmented Test set Accuracy: \", acc_svm_test_aug)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model = KNeighborsClassifier()\n",
    "KNN_model_aug = KNeighborsClassifier()\n",
    "\n",
    "KNN_model.fit(x_train, y_train)\n",
    "KNN_model_aug.fit(x_train_aug, y_train_aug)\n",
    "\n",
    "print(\"KNN Model Trained\")\n",
    "\n",
    "# prediction\n",
    "KNN_predict = KNN_model.predict(x_test)\n",
    "KNN_predict_aug = KNN_model.predict(x_test_aug)\n",
    "\n",
    "# calculating the accuracy\n",
    "acc_knn_train = metrics.accuracy_score(y_train, KNN_model.predict(x_train))\n",
    "acc_knn_test = metrics.accuracy_score(y_test, KNN_predict)\n",
    "\n",
    "print(\"Train set Accuracy: \", acc_knn_train)\n",
    "print(\"Test set Accuracy: \", acc_knn_test)\n",
    "\n",
    "acc_knn_train_aug = metrics.accuracy_score(y_train_aug, KNN_model_aug.predict(x_train_aug))\n",
    "acc_knn_test_aug = metrics.accuracy_score(y_test, KNN_predict_aug)\n",
    "\n",
    "print(\"Augmented Train set Accuracy: \", acc_knn_train_aug)\n",
    "print(\"Augmented Test set Accuracy: \", acc_knn_test_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model_aug = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# training\n",
    "logistic_model.fit(x_train, y_train_raw)\n",
    "logistic_model_aug.fit(x_train_aug, y_train_raw_aug)\n",
    "\n",
    "print(\"linear regression Model Trained\")\n",
    "\n",
    "# prediction\n",
    "logistic_predict = logistic_model.predict(x_test)\n",
    "logistic_predict_aug = logistic_model_aug.predict(x_test_aug)\n",
    "\n",
    "# calculating the accuracy\n",
    "acc_logistic_train = metrics.accuracy_score(y_train_raw, logistic_model.predict(x_train))\n",
    "acc_logistic_test = metrics.accuracy_score(y_test_raw, logistic_predict)\n",
    "\n",
    "print(\"Train set Accuracy: \", acc_logistic_train)\n",
    "print(\"Test set Accuracy: \", acc_logistic_test)\n",
    "\n",
    "acc_logistic_train_aug = metrics.accuracy_score(y_train_raw_aug, logistic_model_aug.predict(x_train_aug))\n",
    "acc_logistic_test_aug = metrics.accuracy_score(y_test_raw, logistic_predict_aug)\n",
    "\n",
    "print(\"Augmented Train set Accuracy: \", acc_logistic_train_aug)\n",
    "print(\"Augmented Test set Accuracy: \", acc_logistic_test_aug)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Descision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_depth = 25\n",
    "\n",
    "dtc_model = DecisionTreeClassifier(max_depth= max_depth)\n",
    "dtc_model_aug = DecisionTreeClassifier(max_depth= max_depth)\n",
    "\n",
    "# training the model\n",
    "dtc_model.fit(x_train, y_train)\n",
    "dtc_model_aug.fit(x_train_aug, y_train_aug)\n",
    "\n",
    "print(\"Descision Tree Model Trained\")\n",
    "\n",
    "# predicting the model\n",
    "dtc_predict = dtc_model.predict(x_test)\n",
    "dtc_predict_aug = dtc_model_aug.predict(x_test_aug)\n",
    "\n",
    "# calculating the accuracy\n",
    "acc_dtc_train = metrics.accuracy_score(y_train, dtc_model.predict(x_train))\n",
    "acc_dtc_test = metrics.accuracy_score(y_test, dtc_predict)\n",
    "\n",
    "print(\"Train set Accuracy: \", acc_dtc_train)\n",
    "print(\"Test set Accuracy: \", acc_dtc_test)\n",
    "\n",
    "acc_dtc_train_aug = metrics.accuracy_score(y_train_aug, dtc_model_aug.predict(x_train_aug))\n",
    "acc_dtc_test_aug = metrics.accuracy_score(y_test, dtc_predict_aug)\n",
    "\n",
    "print(\"Augmented Train set Accuracy: \", acc_dtc_train_aug)\n",
    "print(\"Augmented Test set Accuracy: \", acc_dtc_test_aug)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the results of the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing the results of prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = ['MLP Model', 'SVM', 'KNN', 'Logistic Regression', 'Descision Tree']\n",
    "x_org = [acc_mlp_test, acc_svm_test, acc_knn_test, acc_logistic_test, acc_dtc_test]\n",
    "x_aug = [acc_mlp_test_aug, acc_svm_test_aug, acc_knn_test_aug, acc_logistic_test_aug, acc_dtc_test_aug]\n",
    "\n",
    "x = np.arange(len(x_org))\n",
    "\n",
    "plt.bar(x - 0.2, x_org, 0.4, label = 'Original Data')\n",
    "plt.bar(x + 0.2, x_aug, 0.4, label = 'Augmented Data')\n",
    "plt.xticks(x, x_label)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy of Test Data\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = ['MLP Model', 'SVM', 'KNN', 'Logistic Regression', 'Descision Tree']\n",
    "x_org = [acc_mlp_train, acc_svm_train, acc_knn_train, acc_logistic_train, acc_dtc_train]\n",
    "x_aug = [acc_mlp_train_aug, acc_svm_train_aug, acc_knn_train_aug, acc_logistic_train_aug, acc_dtc_train_aug]\n",
    "\n",
    "x = np.arange(len(x_org))\n",
    "\n",
    "plt.bar(x - 0.2, x_org, 0.4, label = 'Original Data')\n",
    "plt.bar(x + 0.2, x_aug, 0.4, label = 'Augmented Data')\n",
    "plt.xticks(x, x_label)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy of Test Data\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
