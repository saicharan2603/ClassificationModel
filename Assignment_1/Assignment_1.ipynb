{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "MLP Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "\n",
    "# add the path of the Assignment_1 folder to the sys.path\n",
    "sys.path.append('Assignment_1')\n",
    "\n",
    "import numpy as np\n",
    "from Utils import GetData\n",
    "from Tests import PickleTest, FeatureVectorGeneratorTest\n",
    "from PreProcessor import FeatureVectorGenerator\n",
    "from Model.mlp_model import FCLayer, ActivationLayer, Network\n",
    "from Model.activation_error_functions import relu, relu_prime, softmax, softmax_prime, cross_entropy, cross_entropy_prime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Assignment_1\\\\Data\\\\data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/snap/snapd-desktop-integration/49/Downloads/CS776/Assignment_1/Utils/GetData.py:21\u001b[0m, in \u001b[0;36mget_train_data\u001b[0;34m(set)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m unpickle(\u001b[39m\"\u001b[39;49m\u001b[39mAssignment_1/Data/data_batch_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/snap/snapd-desktop-integration/49/Downloads/CS776/Assignment_1/PreProcessor/unpickle.py:5\u001b[0m, in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fo:\n\u001b[1;32m      6\u001b[0m     \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(fo, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Assignment_1/Data/data_batch_1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# importing the raw data by unpickling the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m raw_data \u001b[39m=\u001b[39m GetData\u001b[39m.\u001b[39;49mget_train_data(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m raw_labels \u001b[39m=\u001b[39m GetData\u001b[39m.\u001b[39mget_labels()\n\u001b[1;32m      5\u001b[0m raw_test_data \u001b[39m=\u001b[39m GetData\u001b[39m.\u001b[39mget_test_data()\n",
      "File \u001b[0;32m~/snap/snapd-desktop-integration/49/Downloads/CS776/Assignment_1/Utils/GetData.py:23\u001b[0m, in \u001b[0;36mget_train_data\u001b[0;34m(set)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[39mreturn\u001b[39;00m unpickle(\u001b[39m\"\u001b[39m\u001b[39mAssignment_1/Data/data_batch_1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         \u001b[39mreturn\u001b[39;00m unpickle(\u001b[39m\"\u001b[39;49m\u001b[39mAssignment_1\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mData\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdata_batch_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mset\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/snap/snapd-desktop-integration/49/Downloads/CS776/Assignment_1/PreProcessor/unpickle.py:5\u001b[0m, in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munpickle\u001b[39m(file):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Source code to unpickle the data from\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m# https://www.cs.toronto.edu/~kriz/cifar.html\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fo:\n\u001b[1;32m      6\u001b[0m         \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(fo, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Assignment_1\\\\Data\\\\data_batch_1'"
     ]
    }
   ],
   "source": [
    "# importing the raw data by unpickling the data\n",
    "raw_data = GetData.get_train_data(1)\n",
    "raw_labels = GetData.get_labels()\n",
    "\n",
    "raw_test_data = GetData.get_test_data()\n",
    "\n",
    "# Testing the input data\n",
    "PickleTest.test_data(raw_data)\n",
    "PickleTest.test_labels(raw_labels)\n",
    "\n",
    "x_train = np.zeros((raw_data[b'data'].shape[0], 512))\n",
    "x_test = np.zeros((raw_data[b'data'].shape[0], 512))\n",
    "\n",
    "# declaring the batch size\n",
    "batch_size = 1024\n",
    "\n",
    "for i in range(0, raw_data[b'data'].shape[0], batch_size):\n",
    "    x_train[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data[b'data'][i:i+batch_size])\n",
    "    x_test[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_test_data[b'data'][i:i+batch_size])\n",
    "\n",
    "# one hot encoding the data to get y matrix\n",
    "y_train = FeatureVectorGenerator.one_hot_encoding(raw_data[b'labels'])\n",
    "y_test = FeatureVectorGenerator.one_hot_encoding(raw_test_data[b'labels'])\n",
    "\n",
    "# Testing the feature vector and one hot encoded labels\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data[b'data'], x_train)\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_test_data[b'data'], x_test)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data[b'labels'], y_train)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_test_data[b'labels'], y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(512, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 10))\n",
    "net.add(ActivationLayer(softmax, softmax_prime))\n",
    "\n",
    "# train\n",
    "net.use(cross_entropy, cross_entropy_prime)\n",
    "net.fit(x_train, y_train, epochs=10, learning_rate=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, net.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
