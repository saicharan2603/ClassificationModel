{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "MLP Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "\n",
    "# add the path of the Assignment_1 folder to the sys.path\n",
    "sys.path.append('Assignment_1')\n",
    "\n",
    "import numpy as np\n",
    "from Utils import GetData\n",
    "from Tests import PickleTest, FeatureVectorGeneratorTest\n",
    "from PreProcessor import FeatureVectorGenerator\n",
    "from PreProcessor.unpickle import unpickle\n",
    "from Model.mlp_model import FCLayer, ActivationLayer, Network\n",
    "from Model.activation_error_functions import relu, relu_prime, softmax, softmax_prime, cross_entropy, cross_entropy_prime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Feature Vector Data is greater than 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m y_test_raw \u001b[39m=\u001b[39m raw_test_data[\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[39m# Testing the feature vector and one hot encoded labels\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m FeatureVectorGeneratorTest\u001b[39m.\u001b[39;49mtest_feature_vector_data(raw_data_1[\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m], x_train_1)\n\u001b[1;32m     61\u001b[0m FeatureVectorGeneratorTest\u001b[39m.\u001b[39mtest_feature_vector_data(raw_data_2[\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m], x_train_2)\n\u001b[1;32m     62\u001b[0m FeatureVectorGeneratorTest\u001b[39m.\u001b[39mtest_feature_vector_data(raw_data_3[\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m], x_train_3)\n",
      "File \u001b[0;32m~/snap/snapd-desktop-integration/49/Downloads/CS776/Assignment_1/Tests/FeatureVectorGeneratorTest.py:21\u001b[0m, in \u001b[0;36mtest_feature_vector_data\u001b[0;34m(original_data, feature_vector_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39massert\u001b[39;00m feature_vector_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m512\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFeature Vector Data is not 512\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39massert\u001b[39;00m feature_vector_data\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat32, \u001b[39m\"\u001b[39m\u001b[39mFeature Vector Data is not np.float32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mmax(feature_vector_data) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m , \u001b[39m\"\u001b[39m\u001b[39mFeature Vector Data is greater than 1\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Feature Vector Data is greater than 1"
     ]
    }
   ],
   "source": [
    "# importing the raw data by unpickling the data\n",
    "raw_data_1 = GetData.get_train_data(1)\n",
    "raw_data_2 = GetData.get_train_data(2)\n",
    "raw_data_3 = GetData.get_train_data(3)\n",
    "raw_data_4 = GetData.get_train_data(4)\n",
    "raw_data_5 = GetData.get_train_data(5)\n",
    "\n",
    "raw_labels = GetData.get_labels()\n",
    "\n",
    "raw_test_data = GetData.get_test_data()\n",
    "\n",
    "# Testing the input data\n",
    "PickleTest.test_data(raw_data_1)\n",
    "PickleTest.test_data(raw_data_2)\n",
    "PickleTest.test_data(raw_data_3)\n",
    "PickleTest.test_data(raw_data_4)\n",
    "PickleTest.test_data(raw_data_5)\n",
    "PickleTest.test_data(raw_test_data)\n",
    "\n",
    "PickleTest.test_labels(raw_labels)\n",
    "\n",
    "x_train_1 = np.zeros((raw_data_1[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_2 = np.zeros((raw_data_2[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_3 = np.zeros((raw_data_3[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_4 = np.zeros((raw_data_4[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_5 = np.zeros((raw_data_5[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "x_test = np.zeros((raw_data_1[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "# declaring the batch size\n",
    "batch_size = 1024\n",
    "\n",
    "for i in range(0, raw_data_1[b'data'].shape[0], batch_size):\n",
    "    x_train_1[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_1[b'data'][i:i+batch_size])\n",
    "    x_train_2[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_2[b'data'][i:i+batch_size])\n",
    "    x_train_3[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_3[b'data'][i:i+batch_size])\n",
    "    x_train_4[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_4[b'data'][i:i+batch_size])\n",
    "    x_train_5[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_5[b'data'][i:i+batch_size])\n",
    "\n",
    "    x_test[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_test_data[b'data'][i:i+batch_size])\n",
    "\n",
    "# one hot encoding the data to get y matrix\n",
    "y_train_1 = FeatureVectorGenerator.one_hot_encoding(raw_data_1[b'labels'])\n",
    "y_train_2 = FeatureVectorGenerator.one_hot_encoding(raw_data_2[b'labels'])\n",
    "y_train_3 = FeatureVectorGenerator.one_hot_encoding(raw_data_3[b'labels'])\n",
    "y_train_4 = FeatureVectorGenerator.one_hot_encoding(raw_data_4[b'labels'])\n",
    "y_train_5 = FeatureVectorGenerator.one_hot_encoding(raw_data_5[b'labels'])\n",
    "\n",
    "y_test = FeatureVectorGenerator.one_hot_encoding(raw_test_data[b'labels'])\n",
    "\n",
    "y_train_raw1 = raw_data_1[b'labels']\n",
    "y_train_raw2 = raw_data_2[b'labels']\n",
    "y_train_raw3 = raw_data_3[b'labels']\n",
    "y_train_raw4 = raw_data_4[b'labels']\n",
    "y_train_raw5 = raw_data_5[b'labels']\n",
    "\n",
    "y_test_raw = raw_test_data[b'labels']\n",
    "\n",
    "# Testing the feature vector and one hot encoded labels\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data_1[b'data'], x_train_1)\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data_2[b'data'], x_train_2)\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data_3[b'data'], x_train_3)\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data_4[b'data'], x_train_4)\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_data_5[b'data'], x_train_5)\n",
    "\n",
    "FeatureVectorGeneratorTest.test_feature_vector_data(raw_test_data[b'data'], x_test)\n",
    "\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data_1[b'labels'], y_train_1)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data_2[b'labels'], y_train_2)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data_3[b'labels'], y_train_3)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data_4[b'labels'], y_train_4)\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_data_5[b'labels'], y_train_5)\n",
    "\n",
    "FeatureVectorGeneratorTest.test_one_hot_encoding(raw_test_data[b'labels'], y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(512, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 10))\n",
    "net.add(ActivationLayer(softmax, softmax_prime))\n",
    "\n",
    "# train\n",
    "net.use(cross_entropy, cross_entropy_prime)\n",
    "net.fit(x_train, y_train, epochs=10, learning_rate=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, net.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Machine Learning models Using the scikit learn package\n",
    "\n",
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Trained\n",
      "Train set Accuracy:  0.3893\n",
      "Test set Accuracy:  0.3895\n",
      "f1 score: 0.38233072206707175\n",
      "jaccard score: 0.23981269418893864\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "for i in range(epochs):\n",
    "    svm_model.fit(x_train_1, y_train_raw1)\n",
    "    svm_model.fit(x_train_2, y_train_raw2)\n",
    "    svm_model.fit(x_train_3, y_train_raw3)\n",
    "    svm_model.fit(x_train_4, y_train_raw4)\n",
    "    svm_model.fit(x_train_5, y_train_raw5)\n",
    "\n",
    "svm_predict = svm_model.predict(x_test)\n",
    "print(\"SVM Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train_raw1, svm_model.predict(x_train_1)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test_raw, svm_predict))\n",
    "print(\"f1 score:\",f1_score(y_test_raw, svm_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test_raw, svm_predict, average = \"weighted\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Trained\n",
      "Train set Accuracy:  0.1469\n",
      "Test set Accuracy:  0.1533\n",
      "f1 score: 0.22191751443828625\n",
      "jaccard score: 0.12722637305224943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "epochs = 10\n",
    "KNN_model = KNeighborsClassifier()\n",
    "for i in range(epochs):\n",
    "    KNN_model.fit(x_train_1, y_train_1)\n",
    "    KNN_model.fit(x_train_2, y_train_2)\n",
    "    KNN_model.fit(x_train_3, y_train_3)\n",
    "    KNN_model.fit(x_train_4, y_train_4)\n",
    "    KNN_model.fit(x_train_5, y_train_5)\n",
    "\n",
    "KNN_predict = KNN_model.predict(x_test)\n",
    "print(\"KNN Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train_1, KNN_model.predict(x_train_1)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test, KNN_predict))\n",
    "print(\"f1 score:\",f1_score(y_test, KNN_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test, KNN_predict, average = \"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efdf6480716a66e599b2471050f5d2ee24166bdf10628237c5e64bccecd560c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
