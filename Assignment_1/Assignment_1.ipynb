{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "MLP Model Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "\n",
    "# add the path of the Assignment_1 folder to the sys.path\n",
    "sys.path.append('Assignment_1')\n",
    "\n",
    "import numpy as np\n",
    "from Utils import GetData\n",
    "from Tests import PickleTest, FeatureVectorGeneratorTest\n",
    "from PreProcessor import FeatureVectorGenerator\n",
    "from PreProcessor.unpickle import unpickle\n",
    "from Model.mlp_model import FCLayer, ActivationLayer, Network\n",
    "from Model.activation_error_functions import relu, relu_prime, softmax, softmax_prime, cross_entropy, cross_entropy_prime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/saicharanm22/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# importing the raw data by unpickling the data\n",
    "raw_data_1 = GetData.get_train_data(1)\n",
    "raw_data_2 = GetData.get_train_data(2)\n",
    "raw_data_3 = GetData.get_train_data(3)\n",
    "raw_data_4 = GetData.get_train_data(4)\n",
    "raw_data_5 = GetData.get_train_data(5)\n",
    "\n",
    "raw_labels = GetData.get_labels()\n",
    "\n",
    "raw_test_data = GetData.get_test_data()\n",
    "\n",
    "# Testing the input data\n",
    "PickleTest.test_data(raw_data_1)\n",
    "PickleTest.test_data(raw_data_2)\n",
    "PickleTest.test_data(raw_data_3)\n",
    "PickleTest.test_data(raw_data_4)\n",
    "PickleTest.test_data(raw_data_5)\n",
    "PickleTest.test_data(raw_test_data)\n",
    "\n",
    "PickleTest.test_labels(raw_labels)\n",
    "\n",
    "x_train_1 = np.zeros((raw_data_1[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_2 = np.zeros((raw_data_2[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_3 = np.zeros((raw_data_3[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_4 = np.zeros((raw_data_4[b'data'].shape[0], 512)).astype(np.float32)\n",
    "x_train_5 = np.zeros((raw_data_5[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "x_test = np.zeros((raw_data_1[b'data'].shape[0], 512)).astype(np.float32)\n",
    "\n",
    "# declaring the batch size\n",
    "batch_size = 1024\n",
    "\n",
    "for i in range(0, raw_data_1[b'data'].shape[0], batch_size):\n",
    "    x_train_1[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_1[b'data'][i:i+batch_size])\n",
    "    x_train_2[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_2[b'data'][i:i+batch_size])\n",
    "    x_train_3[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_3[b'data'][i:i+batch_size])\n",
    "    x_train_4[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_4[b'data'][i:i+batch_size])\n",
    "    x_train_5[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_data_5[b'data'][i:i+batch_size])\n",
    "\n",
    "    x_test[i:i+batch_size] = FeatureVectorGenerator.generate_feature_vector(raw_test_data[b'data'][i:i+batch_size])\n",
    "\n",
    "x_train = np.vstack((x_train_1, x_train_2, x_train_3, x_train_4, x_train_5))\n",
    "\n",
    "# one hot encoding the data to get y matrix\n",
    "\n",
    "y_train_1 = FeatureVectorGenerator.one_hot_encoding(raw_data_1[b'labels'])\n",
    "y_train_2 = FeatureVectorGenerator.one_hot_encoding(raw_data_2[b'labels'])\n",
    "y_train_3 = FeatureVectorGenerator.one_hot_encoding(raw_data_3[b'labels'])\n",
    "y_train_4 = FeatureVectorGenerator.one_hot_encoding(raw_data_4[b'labels'])\n",
    "y_train_5 = FeatureVectorGenerator.one_hot_encoding(raw_data_5[b'labels'])\n",
    "\n",
    "y_train = np.vstack((y_train_1, y_train_2, y_train_3, y_train_4, y_train_5))\n",
    "\n",
    "\n",
    "y_test = FeatureVectorGenerator.one_hot_encoding(raw_test_data[b'labels'])\n",
    "\n",
    "y_train_raw_1 = raw_data_1[b'labels']\n",
    "y_train_raw_2 = raw_data_2[b'labels']\n",
    "y_train_raw_3 = raw_data_3[b'labels']\n",
    "y_train_raw_4 = raw_data_4[b'labels']\n",
    "y_train_raw_5 = raw_data_5[b'labels']\n",
    "\n",
    "y_train_raw = np.hstack((y_train_raw_1, y_train_raw_2, y_train_raw_3, y_train_raw_4, y_train_raw_5))\n",
    "assert len(y_train_raw) == 5*10000, f\"Length not correct {y_train_raw.shape}\"\n",
    "\n",
    "y_test_raw = raw_test_data[b'labels']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(512, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 64))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(64, 10))\n",
    "net.add(ActivationLayer(softmax, softmax_prime))\n",
    "\n",
    "# train\n",
    "net.use(cross_entropy, cross_entropy_prime)\n",
    "net.fit(x_train, y_train, epochs=10, learning_rate=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, net.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Machine Learning models Using the scikit learn package\n",
    "\n",
    "1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Trained\n",
      "Train set Accuracy:  0.3893\n",
      "Test set Accuracy:  0.3895\n",
      "f1 score: 0.38233072206707175\n",
      "jaccard score: 0.23981269418893864\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "for i in range(epochs):\n",
    "    svm_model.fit(x_train, y_train_raw)\n",
    "\n",
    "svm_predict = svm_model.predict(x_test)\n",
    "print(\"SVM Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train_raw, svm_model.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test_raw, svm_predict))\n",
    "print(\"f1 score:\",f1_score(y_test_raw, svm_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test_raw, svm_predict, average = \"weighted\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Trained\n",
      "Train set Accuracy:  0.1469\n",
      "Test set Accuracy:  0.1533\n",
      "f1 score: 0.22191751443828625\n",
      "jaccard score: 0.12722637305224943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "epochs = 10\n",
    "KNN_model = KNeighborsClassifier()\n",
    "for i in range(epochs):\n",
    "    KNN_model.fit(x_train, y_train)\n",
    "\n",
    "KNN_predict = KNN_model.predict(x_test)\n",
    "print(\"KNN Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train, KNN_model.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test, KNN_predict))\n",
    "print(\"f1 score:\",f1_score(y_test, KNN_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test, KNN_predict, average = \"weighted\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression Model Trained\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlinear regression Model Trained\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score, jaccard_score, accuracy_score\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain set Accuracy: \u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(y_train_raw, linear_model\u001b[39m.\u001b[39;49mpredict(x_train)))\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest set Accuracy: \u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(y_test_raw, linear_predict))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mf1 score:\u001b[39m\u001b[39m\"\u001b[39m,f1_score(y_test, linear_predict, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "epochs = 10\n",
    "linear_model = LinearRegression()\n",
    "for i in range(epochs):\n",
    "    linear_model.fit(x_train, y_train_raw)\n",
    "\n",
    "linear_predict = linear_model.predict(x_test)\n",
    "print(\"linear regression Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train_raw, linear_model.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test_raw, linear_predict))\n",
    "print(\"f1 score:\",f1_score(y_test, linear_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test, linear_predict, average = \"weighted\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descision Tree Model Trained\n",
      "Train set Accuracy:  1.0\n",
      "Test set Accuracy:  0.4592\n",
      "f1 score: 0.4594516952711894\n",
      "jaccard score: 0.30196243883881596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "epochs = 10\n",
    "dtc_model = DecisionTreeClassifier()\n",
    "for i in range(epochs):\n",
    "    dtc_model.fit(x_train, y_train)\n",
    "\n",
    "dtc_predict = dtc_model.predict(x_test)\n",
    "print(\"Descision Tree Model Trained\")\n",
    "\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "print(\"Train set Accuracy: \", accuracy_score(y_train, dtc_model.predict(x_train)))\n",
    "print(\"Test set Accuracy: \", accuracy_score(y_test, dtc_predict))\n",
    "print(\"f1 score:\",f1_score(y_test, dtc_predict, average='weighted'))\n",
    "print(\"jaccard score:\",jaccard_score(y_test, dtc_predict, average = \"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
